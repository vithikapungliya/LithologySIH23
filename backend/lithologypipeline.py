# -*- coding: utf-8 -*-
"""LithologyPipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1545W3B2tb7riMmsL8avoNpE6ept7uCs9
"""

from keras.preprocessing import image
import torch
model = torch.hub.load('ultralytics/yolov5', 'custom', 'CoreRow.pt')  # custom trained model
import base64
# from keras.models import load_model
import pickle
# model_class=load_model('SelectiveDataset30NoAug.h5')
with open('svc.pkl', 'rb') as file:
    svc_model = pickle.load(file)
"""# YOLO Prediction"""

# Inference



import numpy as np
from skimage import io, color, util
from skimage.filters import gabor
import matplotlib.pyplot as plt
import pandas as pd
import cv2
import numpy as np
from scipy.ndimage import convolve
import os
def calculate_ngtdm(image, distance=1):
    # Convert the image to grayscale if it's a color image
    if len(image.shape) == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Define the NGTDM kernel
    kernel = np.ones((2 * distance + 1, 2 * distance + 1))

    # Convolve the image with the NGTDM kernel
    ngtdm_map = convolve(image, kernel, mode='constant', cval=0.0)

    # Calculate NGTDM features
    unique_values, counts = np.unique(ngtdm_map, return_counts=True)
    
    # Normalize counts to obtain probabilities
    probabilities = counts / np.sum(counts)

    # Calculate NGTDM features
    ngtdm_energy = np.sum(probabilities**2)
    ngtdm_contrast = np.sum((unique_values - np.mean(ngtdm_map))**2 * probabilities)

    return ngtdm_energy, ngtdm_contrast
def load_image(file_path):
    image = cv2.imread(file_path)
    # Convert the image to grayscale if it's not already
    if image.ndim == 3:
        image = color.rgb2gray(image)
    return image

def compute_gabor_features(image, frequencies=[0.1, 0.5], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):
    gabor_features = []
    for freq in frequencies:
        for angle in angles:
            filt_real, filt_imag = gabor(image, frequency=freq, theta=angle)
            gabor_energy = np.sum(filt_real*2 + filt_imag*2)
            gabor_features.append(gabor_energy)
    return gabor_features

def load(file_path):
    # Load the image
    image = load_image(file_path)

    # Compute Gabor features
    ngtdm_energy,ngtdm_contrast = calculate_ngtdm(image)

    # print("ngtdm Texture Features:")
    return ngtdm_energy,ngtdm_contrast

def extract_color_features(image):
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    # Calculate histogram for each channel
    h_hist = cv2.calcHist([hsv_image], [0], None, [256], [0, 256])
    s_hist = cv2.calcHist([hsv_image], [1], None, [256], [0, 256])
    v_hist = cv2.calcHist([hsv_image], [2], None, [256], [0, 256])

    # Normalize histograms
    h_hist /= h_hist.sum()
    s_hist /= s_hist.sum()
    v_hist /= v_hist.sum()

    # Flatten and concatenate histograms
    color_features = np.concatenate([h_hist.flatten(), s_hist.flatten(), v_hist.flatten()])

    return color_features

def prediction(image):
  if image.ndim == 3:
        image_gray = color.rgb2gray(image)
  ngtdm_energy,ngtdm_contrast = calculate_ngtdm(image_gray)
  # ngtdm_energy,ngtdm_contrast=load(image_path)
  # image=cv2.imread(image_path)
  image=cv2.resize(image,(64,64))
  features=extract_color_features(image)
  mean_feature=np.mean(features)
  # print(features.shape)
  df_testing = pd.DataFrame([features], columns=['Feature ' + str(i) for i in range(1,features.shape[0]+1)])
  # print(df_testing)
  df_testing["Energy"]=ngtdm_energy
  df_testing["Entropy"]=ngtdm_contrast
  # print(df_testing)
  pred=svc_model.predict(df_testing)
  return pred,mean_feature,ngtdm_energy,ngtdm_contrast

import cv2
import numpy as np
def draw_bounding_boxes(image_path, df):
    # Read the image using OpenCV
    image = cv2.imread(image_path)

    # Iterate through rows and draw bounding boxes with confidence
    for index, row in df.iterrows():
        xmin, ymin, xmax, ymax = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])
        confidence = row['confidence']

        # Draw bounding box with reduced thickness
        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)  # Green color for the bounding box

    # Draw text after drawing bounding boxes to avoid obscuring the text
    for index, row in df.iterrows():
        xmin, ymin, xmax, ymax = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])
        confidence = row['confidence']

        # Set the font and text properties
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.4
        font_thickness = 1  # Reduced thickness for the text
        font_color = (0, 0, 0)  # Black text color

        # Calculate text size to determine position
        (text_width, text_height), baseline = cv2.getTextSize(f"Confidence: {confidence:.2f}", font, font_scale, font_thickness)

        # Set a minimum vertical space between text and bounding box
        vertical_space = 3

        # Adjust the text position based on the bounding box
        text_position = (xmin + 100, max(ymin - vertical_space, text_height + vertical_space))

        # Draw bounding box
        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 1)  # Green color for the bounding box

        # Draw text on the image
        cv2.putText(image, f"Confidence: {confidence:.2f}", text_position, font, font_scale, font_color, font_thickness, cv2.LINE_AA)

    cv2.imwrite("static/temp_images/output/bounding_box.jpg",image)
    # Display the image with bounding boxes and confidence
    return image

 #Number 1 Output on website

"""# Cropping Each Image to find the core rows"""

def crop(row,file_path):
  image = cv2.imread(file_path)
  x_min, y_min, x_max, y_max = row["xmin"], row["ymin"], row["xmax"], row["ymax"]
  cropped_image = image[int(y_min):int(y_max), int(x_min):int(x_max)]
  return cropped_image



def crop_images(im,df):
  image_list=[]
  for i,row in df.iterrows():
    image_list.append(crop(row,im))
  return image_list
"""# Seperating the Image by n units"""

def divide_image_horizontally(img):


    # Get the width and height of the image
    height, width, _ = img.shape

    # Define the size of each unit
    unit_width = 50 #CHANGE THIS

    # Create the output folder if it doesn't exist
    l=[]
    # Loop through the image horizontally and save each 1-unit slice
    for i in range(0, width, unit_width):
        # Define the region to crop (startY:endY, startX:endX)
        slice_region = img[:, i:i + unit_width, :]
        l.append(slice_region)

        # Save the 1-unit slice to the output folder

    return l
def return_units(image_list):
  all_images_list=[]
  for i in image_list:
    all_images_list.append(divide_image_horizontally(i))
  return all_images_list

"""# Model Loading and Model Prediction"""



"""# Main Algorithm for chemical composition"""
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
def preprocess_image(image_arr):
    # Open the image file
    img_array = cv2.resize(image_arr, (64, 64))

    # Convert the image to a NumPy array
    img_array = np.expand_dims(img_array, axis=0)
    return img_array

# def predict_classes(image_arr):
    # Preprocess the image
    img_array = preprocess_image(image_arr)
    
    # Make predictions
    pred_probs = model_class.predict(img_array)
    
    # Get the predicted class index
    pred_idx = np.argmax(pred_probs, axis=1)
    
    # Map the index to the corresponding class label
    # labels = ["limestone", "sandstone", "shale"]
    # predicted_class = labels[pred_idx[0]]
    
    return pred_probs

def colorize_image(image, predictions):
    colors = {'Limestone': (0, 255, 0),  # Green
              'Sandstone': (0, 0, 255),  # Red
              'Shale': (0, 255, 255)} # yellow

    # Ensure predictions is a list or tuple
    if not isinstance(predictions, (list, tuple)):
        raise ValueError("Predictions must be a list or tuple")

    for pred in predictions:
        class_name = pred['class']
        color = colors.get(class_name, (255, 255, 255))  # Default to white for unknown

        # Draw a rectangle with the specified color
        print(pred)
        cv2.rectangle(image, pred['start_point'], pred['end_point'], color, -1)

    return image

def overall_cylinders(all_images_list,cropped_images):
  list_overall_cylinders=[]
  d={0: "Limestone" , 1: "Sandstone", 2: "Shale"}
  composition_with_path=[]
  counter=0
  for each_cylinder,each_image in zip(all_images_list,cropped_images):
    counter_d={'Limestone': 0, 'Sandstone': 0, 'Shale': 0, 'Unknown':0}
    per_d={}
    out = []
    cnt = 0
    n = len(each_cylinder)
    print(n)
    for unit in each_cylinder:
      pred_class, mean_feature, ngtdm_energy, ngtdm_contrast = prediction(unit)
      # predi=predict_classes(unit
      counter_d[d[pred_class]] += 1
      # counter_d[d[pred_class]]+=1
      out.append({'class': d[pred_class], 'start_point': (cnt * 50, int(400 / n)), 'end_point': (cnt * 50 + 50, 0)})

    _, encoded_image = cv2.imencode('.png', each_image)
    base64_image = base64.b64encode(encoded_image).decode('utf-8')
    cv2.imwrite(f"static/temp_images/output/{counter}.jpg",each_image)
    print(out)
    colored_image = colorize_image(each_image.copy(), out)
    cv2.imwrite(f"static/temp_images/output/{counter}.jpg",colored_image)
    
      
    
    per_d["limestone_percentage"]= round(counter_d["Limestone"]/len(each_cylinder) *100,3)
    per_d["sandstone_percentage"]= round(counter_d["Sandstone"]/len(each_cylinder) *100,3)
    per_d["shale_percentage"]= round(counter_d["Shale"]/len(each_cylinder) *100,3)
    per_d["unknown_percentage"]= round(counter_d["Unknown"]/len(each_cylinder) *100,3)
    composition_with_path.append({f"temp_images/output/{counter}.jpg":per_d})
    #composition_with_path.append({base64_image:per_d})
    counter+=1
    list_overall_cylinders.append(per_d)
  return list_overall_cylinders,composition_with_path
"""Each cylinder composition"""

"""All cylinders composition- Normalization"""

def calculate_overall_composition(cylinder_list):
    total_cylinders = len(cylinder_list)
    overall_composition = {
        'limestone_percentage': 0.0,
        'sandstone_percentage': 0.0,
        'shale_percentage': 0.0,
        'unknown_percentage': 0.0
    }
    for cylinder in cylinder_list:
        overall_composition['limestone_percentage'] += cylinder['limestone_percentage']
        overall_composition['sandstone_percentage'] += cylinder['sandstone_percentage']
        overall_composition['shale_percentage'] += cylinder['shale_percentage']
        # overall_composition['granite_percentage'] += cylinder['granite_percentage']
        overall_composition['unknown_percentage'] += cylinder['unknown_percentage']

    # Normalize the percentages to ensure they add up to 100%
    total_percentage = sum(overall_composition.values())
    
    for key in overall_composition:
          try:
            overall_composition[key] = round((overall_composition[key] / total_percentage) * 100,3)
          except:
             overall_composition[key]=0
       

    return overall_composition



def calculate_composition(image_path):
  image_obj=cv2.imread(image_path)
  cv2.imwrite("original.jpg",cv2.resize(image_obj,(1000,400)))
  results = model("original.jpg")
  results.xyxy[0]  # im predictions (tensor)
  results.pandas().xyxy[0]  # im predictions (pandas)
  df=results.pandas().xyxy[0]
  df=df[df["confidence"]>=0.4]
  bound_image=draw_bounding_boxes("original.jpg", df)
  cropped_images=crop_images("original.jpg",df)
  units=return_units(cropped_images)
  list_overall_cylinders,compostion_with_path=overall_cylinders(units,cropped_images)
  overall_composition_result = calculate_overall_composition(list_overall_cylinders)
  print(list_overall_cylinders)
  return overall_composition_result,compostion_with_path

# calculate_composition("test2.jpg")


